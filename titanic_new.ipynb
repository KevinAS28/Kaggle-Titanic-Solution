{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "titanic_new.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i06vuHq_FLnV",
        "outputId": "30fd5fee-d87e-4ca9-a666-b1c792be44e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "import pandas as pd\n",
        " \n",
        "train = pd.read_csv(\"input/train.csv\")\n",
        "test = pd.read_csv(\"input/test.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0aeb393c354b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input/train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input/test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File input/train.csv does not exist: 'input/train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpOpnuvdu-Dp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_1dclptFLnf",
        "outputId": "29b3b479-13f1-4832-aaba-5da9f8eaadb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "source": [
        "train.head(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f4d577dfc6f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd6FjgEeFLno"
      },
      "source": [
        "col_names = list(train.columns.values)\n",
        "print(col_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3_q3bieFLn2"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B0uhKF-FLn-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoytkyGDFLoF"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRWAZVDtFLoM"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGugdJ06FLoc"
      },
      "source": [
        "test.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brLxbV1fFLoi"
      },
      "source": [
        "train.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGjmyTYlFLop"
      },
      "source": [
        "test.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKBSHhcwFLov"
      },
      "source": [
        "### Data visulatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBUjWQK5FLox"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kUEcdIOFLo3"
      },
      "source": [
        "def bar_chart(feature):\n",
        "    survived = train[train['Survived']==1][feature].value_counts()\n",
        "    dead = train[train['Survived']==0][feature].value_counts()\n",
        "    df = pd.DataFrame([survived, dead])\n",
        "    df.index = ['Survived', 'Dead']\n",
        "    df.plot(kind='bar', stacked=True, figsize=(10, 5))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7NXsz33FLo_"
      },
      "source": [
        "from IPython.core.getipython import get_ipython\n",
        "def create_new_cell(contents):\n",
        "    \n",
        "    shell = get_ipython()\n",
        "\n",
        "    payload = dict(\n",
        "        source='set_next_input',\n",
        "        text=contents,\n",
        "        replace=False,\n",
        "    )\n",
        "    shell.payload_manager.write_payload(payload, single=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0FIOmLfFLpF"
      },
      "source": [
        "for col in col_names:\n",
        "    create_new_cell(f\"bar_chart('{col}')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A08laLYBFLpG"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJKME8d_FLpH"
      },
      "source": [
        "## Name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4luyhcBFLpI"
      },
      "source": [
        "train_test_data = [train, test] # combining train and test dataset\n",
        "\n",
        "for dataset in train_test_data:\n",
        "    dataset['Title'] = dataset['Name'].str.extract('([A-Z|a-z]+)\\.', expand=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_uQkLY8FLpO"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzpPrK_1FLpa"
      },
      "source": [
        "train[\"Title\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52XHaiVeFLpg"
      },
      "source": [
        "test_titles_count = test['Title'].value_counts()\n",
        "test_titles = list(list(test_titles_count.__dict__.values())[1].items)\n",
        "print(test_titles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "MrnFYu8gFLpm"
      },
      "source": [
        "train_titles_count = train['Title'].value_counts()\n",
        "train_titles = list(list(train_titles_count.__dict__.values())[1].items)\n",
        "print(train_titles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKwn_pqgFLps"
      },
      "source": [
        "all_titles = list(set(test_titles+train_titles))\n",
        "all_titles.sort()\n",
        "print(all_titles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yacOXi58FLpy"
      },
      "source": [
        "titles_mapping = dict()\n",
        "\n",
        "index = 0\n",
        "for title in all_titles:\n",
        "    titles_mapping[title] = index\n",
        "    index+=1\n",
        "print(titles_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9aOzojwFLp5"
      },
      "source": [
        "for dataset in train_test_data:\n",
        "    dataset[\"Title\"] = dataset[\"Title\"].map(titles_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSFCJu_XFLp_"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiOUWoD8FLqF"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u-TAxmWFLqN"
      },
      "source": [
        "bar_chart(\"Title\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVld3CkpFLqT"
      },
      "source": [
        "train.drop(\"Name\", axis=1, inplace=True)\n",
        "test.drop(\"Name\", axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XucGMFy6FLqa"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_X1um57FLqh"
      },
      "source": [
        "## Age"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpZuxaplFLqi"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saQYM3uzFLqp"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def get_ds_wo_nan_target(dataset, features=[]):\n",
        "    all_ds_wo_nan_targets = dict()\n",
        "    \n",
        "    if len(features) == 0:\n",
        "        features = list(dataset.columns.values)\n",
        "    \n",
        "    for feat in features:\n",
        "        #get all rows without na except the target\n",
        "        not_feature_targets = list(dataset.columns.values)\n",
        "        del not_feature_targets[not_feature_targets.index(feat)]\n",
        "        \n",
        "        ds_wo_nan_target = dataset\n",
        "        for not_feat_target in not_feature_targets:\n",
        "                ds_wo_nan_target = ds_wo_nan_target[ds_wo_nan_target[not_feat_target].notna()]\n",
        "        \n",
        "        all_ds_wo_nan_targets[feat] = ds_wo_nan_target\n",
        "        \n",
        "    return all_ds_wo_nan_targets\n",
        "\n",
        "def fill_na_with_model(dataset, features=[]):\n",
        "    ds_wo_nan_targets = get_ds_wo_nan_target(dataset, features)\n",
        "    k_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "    scoring = \"accuracy\"\n",
        "    \n",
        "    \n",
        "    for feat in features:\n",
        "        scores = []\n",
        "        classifiers = [SVC(), GaussianNB(), RandomForestClassifier(n_estimators=13), DecisionTreeClassifier(), KNeighborsClassifier(n_neighbors = 13)]\n",
        "        \n",
        "        data = ds_wo_nan_targets[feat]\n",
        "        data.columns = list(dataset.columns.values)\n",
        "        \n",
        "        train = data[data[feat].notna()]\n",
        "        target = train[feat]        \n",
        "        train = train.drop(feat, axis=1)\n",
        "#         print(\"train\")\n",
        "#         print(train.shape)\n",
        "#         print(\"target\")\n",
        "#         print(target.shape)\n",
        "        \n",
        "        \n",
        "        index = 0\n",
        "        for clf in classifiers:\n",
        "            print(f\"clf {index}\")\n",
        "            score = cross_val_score(clf, train, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
        "            score = round(np.mean(score)*100, 6)\n",
        "            scores.append(score)\n",
        "            index += 1\n",
        "    \n",
        "        max_score = max(scores)\n",
        "        max_score_index = scores.index(max_score)\n",
        "        \n",
        "#         print(scores)\n",
        "#         print(max_score_index)\n",
        "        max_clf = classifiers[max_score_index]\n",
        "        max_clf.fit(train, target)\n",
        "        nan_target = data[data[feat].isnull()].drop(feat, axis=1).copy()\n",
        "        result = max_clf.predict(nan_target)\n",
        "        \n",
        "        df_result = pd.DataFrame({feat: result})\n",
        "        \n",
        "        print(\"Feature {} will be filled by model index {} with accuracy {}\".format(str(feat), str(max_score_index),  str(max_score)))\n",
        "        print(result)\n",
        "        \n",
        "        for i, ni in enumerate(nan_target.index[:len(df_result)]):\n",
        "             dataset[feat].loc[ni] = df_result[feat].iloc[i]\n",
        "        \n",
        "    return dataset\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAwgN2gAFLqv"
      },
      "source": [
        "train[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maprS9uGFLq1"
      },
      "source": [
        "test_median = test.groupby(\"Title\")[\"Age\"].transform(\"median\")\n",
        "test[\"Age\"].fillna(test_median, inplace=True)\n",
        "print(test_median)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xPadrATFLrA"
      },
      "source": [
        "for dataset in train_test_data:\n",
        "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0,\n",
        "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1,\n",
        "    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2,\n",
        "    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3,\n",
        "    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGKduVyGFLrF"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "G-5gmIMKFLrN"
      },
      "source": [
        "bar_chart(\"Age\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dTAzwevoFLrR"
      },
      "source": [
        "test.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuDIjs2kFLrX"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ORr-Ix_-FLre"
      },
      "source": [
        "import math\n",
        "test_null = pd.DataFrame(test[\"Age\"].isnull())\n",
        "\n",
        "\n",
        "test_null[test_null[\"Age\"]!=False]\n",
        "test[\"Age\"][88] = 17\n",
        "print(test.loc[[88]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHjWbrFGFLrk"
      },
      "source": [
        "## Embarked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WFsgHv7UFLrl"
      },
      "source": [
        "Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\n",
        "Pclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\n",
        "Pclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\n",
        "df = pd.DataFrame([Pclass1, Pclass2, Pclass3])\n",
        "df.index = ['1st class','2nd class', '3rd class']\n",
        "df.plot(kind='bar',stacked=True, figsize=(10,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYQsgQsvFLrq"
      },
      "source": [
        "for dataset in train_test_data:\n",
        "    dataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(\"S\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QUjlgCLFLru"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hUrCvtXFLr0"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PcKLxVeFLr-"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XohaF-V6FLsF"
      },
      "source": [
        "test.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kPYOaRRFLsL"
      },
      "source": [
        "train[\"Embarked\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_zDWl4rFLsR"
      },
      "source": [
        "test[\"Embarked\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UCwerY9FLsX"
      },
      "source": [
        "embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
        "for dataset in train_test_data:\n",
        "    dataset[\"Embarked\"] = dataset[\"Embarked\"].map(embarked_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwIYeyOEFLsc"
      },
      "source": [
        "## Fare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8KcxHSJwFLsc"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8JCr39eFLsh"
      },
      "source": [
        "# fill missing Fare with median fare for each Pclass\n",
        "train[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\n",
        "test[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\n",
        "train.head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ievzm7_AFLsk"
      },
      "source": [
        "train[\"Fare\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13iqixoTFLsn"
      },
      "source": [
        "def categorize_by_step(dataset, feature, step=5):\n",
        "    minimum = dataset.min(axis=0)[feature]\n",
        "    maximum = dataset.max(axis=0)[feature]\n",
        "    print(\"Feature:\", feature)\n",
        "    print(\"Min:\", minimum)\n",
        "    print(\"Max:\", maximum)\n",
        "    \n",
        "    \n",
        "    limit = minimum + step\n",
        "    \n",
        "    initial_affected_rows = dataset.loc[ dataset[feature] <= limit, feature]\n",
        "    if initial_affected_rows.shape[0] > 0:\n",
        "        dataset.loc[ dataset[feature] <= limit, feature] = 0\n",
        "        print(f\"affected row > 0 ({str(initial_affected_rows)}), fare <= {str(limit)} set to 0\")\n",
        "        index = 1\n",
        "        \n",
        "    else:\n",
        "        index = 0\n",
        "    \n",
        "    max_before = initial_affected_rows.max(axis=0)\n",
        "    \n",
        "    while limit < maximum:\n",
        "        affected_rows = dataset.loc[ (dataset[feature] > max_before) & (dataset[feature] <= (limit + step)), feature]\n",
        "        \n",
        "        if affected_rows.shape[0] > 0:\n",
        "            print(f\"affected row > 0 ({str(affected_rows)}), {str(max_before)} < fare <= {str(limit+step)} set to {str(index)}\")\n",
        "            dataset.loc[ (dataset[feature] > max_before) & (dataset[feature] <= (limit + step)), feature] = index\n",
        "            max_before = affected_rows.max(axis=0)\n",
        "            limit = max_before + step\n",
        "            index += 1\n",
        "        else:\n",
        "            limit += step\n",
        "        \n",
        "    end_affected_rows = dataset.loc[ dataset[feature] >= maximum, feature].shape[0]\n",
        "    if end_affected_rows > 0:\n",
        "        dataset.loc[ dataset[feature] >= maximum, feature] = index\n",
        "        print(f\"affected row > 0 ({str(end_affected_rows)}), fare >= {str(maximum)} set to {str(index)}\")\n",
        "        \n",
        "    print()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kLchg5tLFLst"
      },
      "source": [
        "for dataset in train_test_data:\n",
        "    categorize_by_step(dataset, \"Fare\", 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pxbqHOZeFLsx"
      },
      "source": [
        "train[\"Fare\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur3fXp6GFLs6"
      },
      "source": [
        "## Cabin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsbhehDCFLs8"
      },
      "source": [
        "for dataset in train_test_data:\n",
        "    dataset[\"Cabin\"] = dataset[\"Cabin\"].str[:1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsRWy3LIFLtH"
      },
      "source": [
        "test[\"Cabin\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "PYqK1PmOFLtL"
      },
      "source": [
        "for i in range(1, 4):\n",
        "    print(\"Cabin class:\", i)\n",
        "    print(train[train['Pclass']==i]['Cabin'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHvy3Lv5FLtQ"
      },
      "source": [
        "cabin_mapping = dict()\n",
        "\n",
        "import string\n",
        "index = 0\n",
        "for l in string.ascii_uppercase:\n",
        "    cabin_mapping[l] = index\n",
        "    index+=1\n",
        "    if l == \"F\":\n",
        "        break \n",
        "    \n",
        "print(cabin_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dkvXcNAFLtU"
      },
      "source": [
        "for dataset in train_test_data:\n",
        "    dataset[\"Cabin\"] = dataset[\"Cabin\"].map(cabin_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPi6VUs2FLtc"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E41Q5xbxFLtg"
      },
      "source": [
        "# fill missing Fare with median fare for each Pclass\n",
        "train[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\n",
        "test[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSFKPhd0FLtm"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soVGmyoIFLtr"
      },
      "source": [
        "## Sex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9zGmrDcFLtr"
      },
      "source": [
        "sex_mapping = {\"male\": 0, \"female\": 1}\n",
        "for dataset in train_test_data:\n",
        "    dataset['Sex'] = dataset['Sex'].map(sex_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InPwxfaWFLtw"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RkWRLLTFLtz"
      },
      "source": [
        "## Family size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D7DxfXTFLt0"
      },
      "source": [
        "train[\"SibSp\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K76YoxLFLt2"
      },
      "source": [
        "train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"]\n",
        "test[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuCdsmE8FLt5"
      },
      "source": [
        "train[\"FamilySize\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C82vuw2FLt8"
      },
      "source": [
        "## Before Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fZ4s8ZnYFLt9"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9NDf9a9FLuB"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9YX5smDFLuD"
      },
      "source": [
        "train.to_csv(\"train_cleaned.csv\")\n",
        "test.to_csv(\"test_cleaned.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03yZGa_XFLuG"
      },
      "source": [
        "features_drop = ['Ticket', 'SibSp', 'Parch']\n",
        "train = train.drop(features_drop, axis=1)\n",
        "test = test.drop(features_drop, axis=1)\n",
        "train = train.drop(['PassengerId'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhdi1kqYFLuM"
      },
      "source": [
        "train_data = train.drop('Survived', axis=1)\n",
        "target = train['Survived']\n",
        "\n",
        "train_data.shape, target.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "P5Z5xrbIFLuQ"
      },
      "source": [
        "train_data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QZCIoyFHFLuU"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beBMvtW9FLuY"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skv10UD_FLuY"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeYQd2ovFLuc"
      },
      "source": [
        "### Cross Validation (K-fold)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ7Ux54SFLuc"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvkZB3jeFLug"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve8zsR5aFLuh"
      },
      "source": [
        "clf = KNeighborsClassifier(n_neighbors = 13)\n",
        "scoring = 'accuracy'\n",
        "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEI0D981FLul"
      },
      "source": [
        "# kNN Score\n",
        "round(np.mean(score)*100, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUiNKWNiFLuq"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z3h4hqiFLur"
      },
      "source": [
        "clf = DecisionTreeClassifier()\n",
        "scoring = 'accuracy'\n",
        "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwrZq5XkFLuv"
      },
      "source": [
        "# decision tree Score\n",
        "round(np.mean(score)*100, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBfi4BVGFLuy"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORS4WpShFLuy"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=13)\n",
        "scoring = 'accuracy'\n",
        "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmVCpi59FLu1"
      },
      "source": [
        "# Random Forest Score\n",
        "round(np.mean(score)*100, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIsXVxk9FLu4"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRpY6Ih1FLu5"
      },
      "source": [
        "clf = GaussianNB()\n",
        "scoring = 'accuracy'\n",
        "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwhW2j_RFLu_"
      },
      "source": [
        "# Naive Bayes Score\n",
        "round(np.mean(score)*100, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFNVpmIQFLvD"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72e2WvfVFLvD"
      },
      "source": [
        "clf = SVC()\n",
        "scoring = 'accuracy'\n",
        "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dHl2sSybFLvI"
      },
      "source": [
        "round(np.mean(score)*100,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZjsu_d2FLvL"
      },
      "source": [
        "#Splitting the dataset into  training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "training_set, validation_set = train_test_split(train, test_size = 0.2, random_state = 21)\n",
        "\n",
        "#classifying the predictors and target variables as X and Y\n",
        "X_train = training_set.iloc[:,0:-1].values\n",
        "Y_train = training_set.iloc[:,-1].values\n",
        "X_val = validation_set.iloc[:,0:-1].values\n",
        "y_val = validation_set.iloc[:,-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kotZa_3qFLvO"
      },
      "source": [
        "def accuracy(confusion_matrix):\n",
        "   diagonal_sum = confusion_matrix.trace()\n",
        "   sum_of_all_elements = confusion_matrix.sum()\n",
        "   return diagonal_sum / sum_of_all_elements\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp0 = MLPClassifier(hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=1000)\n",
        "mlp1 = MLPClassifier(hidden_layer_sizes=(150,100,50), max_iter=300,activation = 'relu',solver='adam',random_state=1)\n",
        "mlp0.fit(X_train, Y_train)\n",
        "y_pred = mlp0.predict(X_val)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#Comparing the predictions against the actual observations in y_val\n",
        "cm = confusion_matrix(y_pred, y_val)\n",
        "\n",
        "#Printing the accuracy\n",
        "print(\"Accuracy of MLPClassifier : \", accuracy(cm))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeccV-O2FLvQ"
      },
      "source": [
        "# Testting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MHqULN7FLvR"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=13)\n",
        "clf.fit(train_data, target)\n",
        "\n",
        "test_data = test.drop(\"PassengerId\", axis=1).copy()\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8__Y518FLvT"
      },
      "source": [
        "prediction = clf.predict(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK1IYtHrFLvX"
      },
      "source": [
        "submission = pd.DataFrame({\n",
        "        \"PassengerId\": test[\"PassengerId\"],\n",
        "        \"Survived\": prediction\n",
        "    })\n",
        "\n",
        "submission.to_csv('submission_my.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KQVkYOOFFLvb"
      },
      "source": [
        "submission = pd.read_csv('submission_my.csv')\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_rjIv4LFLvf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}